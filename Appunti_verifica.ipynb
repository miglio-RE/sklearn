{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5115c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier #classificatore\n",
    "from sklearn.model_selection import train_test_split #split in train e test set\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from funzione.py import analisi_grafica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63169935",
   "metadata": {},
   "source": [
    "### verifica Pratica su Regressori e Classificatori:\n",
    "\n",
    "fasi per realizzare un algoritmo di ML:\n",
    "\n",
    "1. Scelta dei dati\n",
    "2. ripulire i dati: eliminare i valori NaN\n",
    "3. suddividere i dati nell'insieme di train e di test\n",
    "4. scelta del modello: regressore o classficatore\n",
    "5. addestrare il modello\n",
    "6. testare il modello\n",
    "7. valutare il modello\n",
    "8. salvare il modello\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34284616",
   "metadata": {},
   "source": [
    "## Scelta dati:\n",
    "\n",
    "lettura dataframe:\n",
    "\n",
    "    #data=pd.read_csv(\"./sp500.csv\", usecols=[\"Date\", \"SP500\"], parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "    data=pd.read_csv(\"./data.csv\", na_values=[-99999.00])\n",
    "    #se il file non ha un header:\n",
    "    data=pd.read_csv('./MonthElb_012010_004028900.csv',header=None,names=['Data','Ora','Id','Comune',\n",
    "                                                                      'Num', 'VelVento','DirVento',\n",
    "                                                                     'DeviazStanVento','Press','TempAria',\n",
    "                                                                     'Umidita','RadiazSolarDiretta','RadiazSolarRif',\n",
    "                                                                     'Pioggia'], na_values=9999.9)\n",
    "\n",
    "\n",
    "    #quando leggiamo un dataset possiamo specificare le colonne\n",
    "    #index_col: data come indici\n",
    "    #parse dates: data nonm come una stringa\n",
    "    data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4b21b9",
   "metadata": {},
   "source": [
    "## Pulizia dati:\n",
    "\n",
    "prima di dare i dati, bisogna eliminare i valori nulli. due possibilità:\n",
    "\n",
    "- eliminarli all'inizio\n",
    "- eliminare i dati nulli solo delle colonne che ci servono, per perdere il minor numero di campione che ci servono\n",
    "\n",
    "Per vedere le collone che contengono valori Nan:\n",
    "\n",
    "\n",
    "    cols_with_missing=[col for col in data.columns if data[col].isnull().sum()]\n",
    "    print(cols_with_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bd7c5e",
   "metadata": {},
   "source": [
    "## Analisi grafica:\n",
    "\n",
    "    selected_cols=[\"culmen_length_mm\", \"culmen_depth_mm\", \"flipper_length_mm\", \"body_mass_g\",\"island_numeric\" ]\n",
    "    #colonne di interesse\n",
    "\n",
    "    analisi_grafica(nuovo_data, \"species\", selected_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6643e84c",
   "metadata": {},
   "source": [
    "Eliminare i valori NaN delle colonne di interesse:\n",
    "\n",
    "    d=data.dropna(axis=\"index\", subset=selected_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ed95da",
   "metadata": {},
   "source": [
    "#  Classificatore:\n",
    "## Split in test e train set:\n",
    "\n",
    "       X=data[[\"feature\"]].values\n",
    "       y=data[\"target\"].values\n",
    "       X_train, X_test, y_train, y_test=train_test_split(X, y, train_size=0.7, random_state=0)\n",
    "# Creazione di un oggetto StandardScaler,  Adattamento e trasformazione dei dati:\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305e1131",
   "metadata": {},
   "source": [
    "\n",
    "Definizione:\n",
    "\n",
    "    model=MLPClassifier(hidden_layer_sizes=(100, 100), random_state=1, max_iter=300)\n",
    "    #hidden_size: numero di nodi nascosti 100 100\n",
    "    #max iter. diciamo al modello di allenarsi 300 volte. impara sui set di allenamento\n",
    "    #per 300 volte scorriamo l'array e per ogni riga specifichiamo le carattteristiche dell'alieno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e025f94",
   "metadata": {},
   "source": [
    "### addestramento modello:\n",
    "\n",
    "    model.fit(X_train_scaled, y)\n",
    "    #con una sola feature: reg.fit(X[:, np.newaxis], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba53a95",
   "metadata": {},
   "source": [
    "## Verifica accuratezza:\n",
    "\n",
    "        print(f\"\"\"\n",
    "\n",
    "    Train:\n",
    "    dati aspettati:\n",
    "    {y_train.values[:5]} \n",
    "    dati dell'algoritmo:\n",
    "    {model.predict(X_train_std[:5])}\n",
    "    \n",
    "    \"\"\")\n",
    "\n",
    "    print(f\"Accuratezza set TRAIN: {model.score(X_train_std, y_train)}\")\n",
    "    print(f\"Accuratezza set TEST: {model.score(X_test_std, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bb61b8",
   "metadata": {},
   "source": [
    "validazione modello:\n",
    "\n",
    "    start=100\n",
    "    stop=300\n",
    "    passo=10\n",
    "    vEposch=np.arange(start, stop, passo)\n",
    "    vAccTrain=[]\n",
    "    vAccTest=[]\n",
    "    for e in vEposch:\n",
    "        mlp=MLPClassifier(hidden_layer_sizes=(100, 100), random_state=1, max_iter=e)\n",
    "        mlp.fit(X_train_std, y_train)\n",
    "        vAccTrain.append(mlp.score(X_train_std, y_train))\n",
    "        vAccTest.append(mlp.score(X_test_std, y_test))\n",
    "    plt.plot(vEposch, vAccTrain, c=\"b\", label=\"Train\")\n",
    "    plt.plot(vEposch, vAccTest, c=\"g\", label=\"Test\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689cc466",
   "metadata": {},
   "source": [
    "## regressore:\n",
    "\n",
    "\n",
    "    reg=LinearRegression()\n",
    "    X=data[[\"feature\"]].values\n",
    "    y=data[[\"target\"]].values\n",
    "    sc_x=StandardScaler()\n",
    "    sc_y=StandardScaler()\n",
    "    X_sc=sc_x.fit_transform(X)\n",
    "    y_sc=sc_y.fit_transform(y)\n",
    "    regressione_2.fit(X_sc, y_sc)#realizza l'apprendimento come la classificazione\n",
    "    #con una sola feature: reg.fit(X[:, np.newaxis], y)\n",
    "    print(f\"\"\"\n",
    "    coefficiente di detrminazione R^2: {reg.score(X_sc, y_scy):.2f}\n",
    "    coefficiente angolare: {reg.coef_[0][0]:.2f}\n",
    "    intercetta: {reg.intercept_[0]:.2f}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7653d2",
   "metadata": {},
   "source": [
    "### Rappresentare la retta di regressione:\n",
    "\n",
    "\n",
    "    fig, ax=plt.subplots( figsize=(6,6))\n",
    "    array_x=np.linspace(30,60, 100)\n",
    "    array_y=m0*array_x+q0\n",
    "    ax.scatter(X0, y, color=np.random.uniform(0,1,3), alpha=0.5)\n",
    "    ax.plot(array_x, array_y, c=\"r\",)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15624459",
   "metadata": {},
   "source": [
    "## Calcolare il valore del Lag:\n",
    "\n",
    "Shiftiamo di un certo valore in modo che la rappresentazione dei dati sia simile ad una retta:\n",
    "       \n",
    "       colonna=data[\"feature\"].values\n",
    "       max_lag=30\n",
    "        for lag in range(1, max_lag):\n",
    "            X=np.roll(colonna, -lag)[:-lag]\n",
    "            y=sales[:-lag]\n",
    "            regressione_2.fit(X[:, np.newaxis], y)\n",
    "            print(f\"\"\"\n",
    "            lag: {lag}\n",
    "            coefficiente di detrminazione R^2: {regressione_2.score(X[:, np.newaxis], y)}\"\"\")\n",
    "            \n",
    "\n",
    "Rappresentazione delle due curve: \n",
    "\n",
    "    lag=19 #ottenuto dal for precedente\n",
    "    colonna_lag=np.roll(colonna_lag, -lag)[:-lag]\n",
    "\n",
    "    fig, ax=plt.subplots(figsize=(9,6))\n",
    "    ax.plot(colonna_1[:-lag], colonna_lag,  label=\"Vendite di sigarette al giorno per persona*10\")\n",
    "    ax.plot(anni, vendite*10, label=\"Tasso mortalità uomini\")\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(\"Anno\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d30039",
   "metadata": {},
   "source": [
    "## Label Encoder:\n",
    "se il dataset ha solo colonne qualitative\n",
    "\n",
    "\n",
    "    colonne_numeriche={}\n",
    "    le_dict={}\n",
    "    for col in colonne:\n",
    "        #trasforma colonne qualitatitive in colonne numeriche\n",
    "        le_dict[col] = LabelEncoder()\n",
    "        colonne_numeriche[col]=le_dict[col].fit_transform(data[col])\n",
    "    colonne_numeriche\n",
    "    nuovo_data=pd.DataFrame(colonne_numeriche)\n",
    "    nuovo_data\n",
    "    le_dict\n",
    "    \n",
    "Se solo alcune colonne sono qualitative, ma  necessarie per l'apprendimento:\n",
    "\n",
    "    label_encoder=LabelEncoder()\n",
    "    \n",
    "    #creazione di una nuova colonna quantitative di un dataframe a partire da una colonna qualitativa\n",
    "    data[\"nuova_colonna\"]=label_encoder.fit_transform(data[\"colonna_qualitativa\"])\n",
    "    \n",
    "Per vedere il valore numerico che corrisponde a un valore qualitativo: \n",
    "    \n",
    "    label_encoder.inverse_transform([3])\n",
    "    \n",
    "Trasformazione inversa: se passiamo il valore numerico e vogliamo sapere il valore qualitativo:\n",
    "\n",
    "    label_encoder.inverse_transform([0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0a416c",
   "metadata": {},
   "source": [
    "più gli istogrammi sono separati, più una feature è importante. \n",
    "\n",
    "se sono attaccati, una solo feature non basta. Non c'è una separazione netta. \n",
    "Per capire se due bastano, trovare due grafici dove gli scatter sono separati, Se non c'è mai una separazione netta, la rete deve usare almeno 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f1ac8",
   "metadata": {},
   "source": [
    "Per prevedere il valore di una regressione o classificatore:\n",
    "    \n",
    "    regressione_2.predict([[valori]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0db0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c5e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
