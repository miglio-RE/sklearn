{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fad3537",
   "metadata": {},
   "source": [
    "esperimento gpt 4, essendo un llm. descrivfi un linguaggio di alto livello\n",
    "NOMECLATURA:\n",
    "LLM: large language model=modello linguistico di grandi dimensioni\n",
    "agente conversazionale: chatbot. Entità con la quale è possibile trattare una conversazione scritta e parlata. ChatGPT è un chatbot.\n",
    "Simulare un'interrogazione\n",
    "i LLm sono reti neurali basati su una tecnologia trasformatori(transformer) per lavorare il testo. Questi trasfromatori generative: capaci di generare testo e apparentemente capaci di comprendere il testo. comprendere: verbi per la nostra coscienza e cervello->non comprende\n",
    "BOOM LLM: OpenAI, 2 anni fa. primo modello: gpt versione 2, versione 3:chatgpt\n",
    "aziende addestrano reti neurali->scissione, 2 politiche:\n",
    "open source: META, fb, inst. LLM llama, gratutito \n",
    "proprietario: OpenAI, google bard\n",
    "una rete neurale è caratterizzata da paramentri: numero\n",
    "più è grande la rete, più i numeri sono grandi.\n",
    "versione 2 Llama->7Miliardi, meno avanazato\n",
    "su un portatile potente e con scheda grafica può girare.\n",
    "chiunque li può eseguire e modificare in locale.\n",
    "TOKEN: llama 2 addestrato su 2 trillioni di TOKEN, libri con copyright che non può usare, ma è stata addestrata\n",
    "OPENAI: modello 3.5 usabile con il chatbot chatgpt\n",
    "modello 4 a pagamento\n",
    "chatgpt 3 e 4, diversi perchè usano reti neurali diversi.\n",
    "3.5 è un puro chatbot: usa testo\n",
    "4: è capace di usare strumenti: ricerche internet, generare immagini e interpretare immagini\n",
    "googlce gemini: oggetto capace di usare strumenti, non solo chatbot\n",
    "chatgpt spezza il testo in token. Libreria python per lo spezzamento in token\n",
    "chatgpt è un autoregressore: previsione  cosa viene dopo, autoregressione: prevdere quello che viene dopo usando quello che ho previsto prima.\n",
    "chatgpt è uno pappagallo stocastico\n",
    "chatgpt capisce quello che scriviamo? hanno un'abilità linguistica formale pazzesca, ed è capace di produrre testo con stile e tono personalizzato.\n",
    "non ha nessuna conoscenza del mondo e situazioni. Non si può dire che capisce quello che dice.\n",
    "chatgpt 3.5 ha un 1,7*10^11 paramentri\n",
    "chatgpt 4 ha un 1,7*10^12 paramentri,, ipotesi: non certificato\n",
    "il nostro cervello è formato da neuroni legate dallw sinapsi, simili ai parametri delle reti neurali e noi ne abbiamo 1*10^$14$.\n",
    "Alcuni scienziati ipotizzano che i miodelli diventeranno intelligenti, non coscienza: provare emozioni e sentimenti.\n",
    "é possibile aumentare il numero di oarametri, aumentando la potenza di calcolo.\n",
    "come funziona il nostro cervello: ha 2 mod di penesiero: sistema 1 e 2.\n",
    "Pensiero 1: sistema di pensiero a costo 0 di fatiica, energia e tempo= istintivo e automatico, emotivo e irrazionale\n",
    "pensiero 2: task più complesse, necessita di un processo\n",
    "chatgpt e LLM hanno solo il sistema 1: impulsivi e irrazionali e non sono in grado si svolgere task complesse\n",
    "sono irrazionali nelle risposte e nei compiti matematici sono pessimi, di conseguebza non possiamo fare affidamento alle riposte che ci danno\n",
    "quando scriviamo un testo a chatgtp: prompt\n",
    "riposta: output\n",
    "ingegneria dei prompt: scrivere prompt per far si che ci diano riposte errate\n",
    "\n",
    "do un'istruzione e un dato, necessario separali con un carattere perchè sono diversi e lui risponde in modo casuale.\n",
    "all'interno di una chat, lui usa quello che generato precedentemente\n",
    "posso insegnare a chatgot delle cose, riesco a istruire il prompt\n",
    "\n",
    "Prompt: quando usiamo UN LLM, il prompt può avere 4 tipi\n",
    "- istruzioni: compito che deve eseguire\n",
    "- contesto: contesto aggiuntivo che possono indirizzare verso riposte migliori\n",
    "- dati in input: domanda per trovare la riposta\n",
    "- indicatore: output che voglio. formato output\n",
    "\n",
    "\n",
    "per un prompt che funzioni bene, dare più volte il prompt fino a quando non funziona bene\n",
    "usare istruzioni precise, in italiano corretto e essere precisi e evitare di scrivere cosa nom fare perchè il non fare richiede un processo logico.\n",
    "\n",
    "bisogna dare il tempo di pensare: bisogna guidarli e aiutarli\n",
    "\n",
    "Per il formato è possibile dare un numero di caratteri, anche se non è capace e di contare sta vicino \n",
    "\n",
    "Brainstorming, argomenti da approfondire->panoramica alto livello\n",
    "pair programming: chatgpt conosce tutte le classi, metodi. Io scrivo il codice e uso chatgpt quando ho dubbi su moduli, libreire con costrutti diversi da nostri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba2273d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
